{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a34c9d5-8dbd-40f2-b85b-aa1f1d73f7bb",
   "metadata": {},
   "source": [
    "# 复现从头开始实现线性回归\n",
    "\n",
    "## 任务分解：\n",
    "- 构建数据集：构造一个函数，并制造对应大小的数据集，并且引入噪声\n",
    "- 实现SGD（小批量随机梯度下降优化器）\n",
    "- 训练并测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f1d1d5-3bff-4da5-8fbf-e2aa78d3a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e7a390-25cd-43f6-b744-9b124c64e0aa",
   "metadata": {},
   "source": [
    "## 构建数据集\n",
    "我们使用 $y=W*x+b,w^T=[2,-3.1,4],b=4.2$ 作为核心函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3198a503-f7b2-4191-8190-d37bc28ee82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets_function(w,b,num_examples):\n",
    "    x = torch.normal(0,1,(num_examples,len(w)))\n",
    "    y = torch.matmul(x,w)+b\n",
    "    y += torch.normal(0,0.01,y.shape)\n",
    "    return x,y.reshape((-1,1))\n",
    "\n",
    "w_true = torch.tensor([2,-3.1,4])\n",
    "b_true = 4.2\n",
    "features,labels = datasets_function(w_true , b_true , 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1dabc92-b60c-4097-bba7-0d0cb71a5e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features tensor([1.9451, 1.0990, 0.3316]) labels tensor([6.0009])\n"
     ]
    }
   ],
   "source": [
    "print('features',features[0],\"labels\",labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a64ed34-ccd5-42a2-9ff5-0e0d39d20b74",
   "metadata": {},
   "source": [
    "## 实现SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fefcbc1-6b34-40d7-a185-ce6c9901b277",
   "metadata": {},
   "source": [
    "### 分批次读取数据集的内容\n",
    "设置一个batch_size然后分批次读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52a66697-7d27-4cc7-8bc9-e9aa379f74f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_reader(features,labels,batchsize):\n",
    "    index = list(range(len(features)))\n",
    "    random.shuffle(index)\n",
    "    for i in range(0,len(features),batchsize):\n",
    "        batch_tensor = torch.tensor(index[i:min(i+batchsize,len(features))])\n",
    "        yield features[batch_tensor],labels[batch_tensor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09c5e3c-ee31-457e-9d89-b5789f389e88",
   "metadata": {},
   "source": [
    "### 实现损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c257ee3-44a7-4527-a59b-5ef197e8ba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y,y_real):\n",
    "    return (y_real.reshape(y.shape)-y)** 2 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa0d134-646f-4a8d-bffe-34ca368bf2f8",
   "metadata": {},
   "source": [
    "### 定义梯度下降和Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4394c9cd-e987-413b-839f-be366950e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(batchsize,lr,params):\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr*param.grad / batchsize\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d816ec6-d65a-4c6e-94a3-06132553c924",
   "metadata": {},
   "source": [
    "## 训练\n",
    "\n",
    "### 模型初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b29bd70-6b20-4590-813d-ab871f1c6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.normal(2,0.01,size=(3,1),requires_grad = True)\n",
    "b = torch.zeros(1,requires_grad = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf4abd5-f8c4-42f1-ba72-6dcc0ee426d1",
   "metadata": {},
   "source": [
    "### 定义超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a348a23d-4a0e-457b-b422-bb70feec192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "epoches = 50\n",
    "batch_size = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570c88d4-f4b7-4553-acf3-01b22d6f7953",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a9daf75-aca7-4b6e-9379-5087f882c855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1,loss7.481070\n",
      "epoch2,loss2.917686\n",
      "epoch3,loss1.516930\n",
      "epoch4,loss0.504966\n",
      "epoch5,loss0.152874\n",
      "epoch6,loss0.055254\n",
      "epoch7,loss0.030557\n",
      "epoch8,loss0.015588\n",
      "epoch9,loss0.005223\n",
      "epoch10,loss0.002142\n",
      "epoch11,loss0.000745\n",
      "epoch12,loss0.000350\n",
      "epoch13,loss0.000097\n",
      "epoch14,loss0.000077\n",
      "epoch15,loss0.000054\n",
      "epoch16,loss0.000094\n",
      "epoch17,loss0.000048\n",
      "epoch18,loss0.000050\n",
      "epoch19,loss0.000067\n",
      "epoch20,loss0.000068\n",
      "epoch21,loss0.000052\n",
      "epoch22,loss0.000057\n",
      "epoch23,loss0.000056\n",
      "epoch24,loss0.000053\n",
      "epoch25,loss0.000058\n",
      "epoch26,loss0.000050\n",
      "epoch27,loss0.000065\n",
      "epoch28,loss0.000044\n",
      "epoch29,loss0.000052\n",
      "epoch30,loss0.000051\n",
      "epoch31,loss0.000057\n",
      "epoch32,loss0.000055\n",
      "epoch33,loss0.000041\n",
      "epoch34,loss0.000051\n",
      "epoch35,loss0.000046\n",
      "epoch36,loss0.000041\n",
      "epoch37,loss0.000061\n",
      "epoch38,loss0.000050\n",
      "epoch39,loss0.000058\n",
      "epoch40,loss0.000043\n",
      "epoch41,loss0.000041\n",
      "epoch42,loss0.000046\n",
      "epoch43,loss0.000058\n",
      "epoch44,loss0.000060\n",
      "epoch45,loss0.000046\n",
      "epoch46,loss0.000026\n",
      "epoch47,loss0.000052\n",
      "epoch48,loss0.000076\n",
      "epoch49,loss0.000033\n",
      "epoch50,loss0.000059\n"
     ]
    }
   ],
   "source": [
    "for epoch in range (epoches):\n",
    "    for x,y in batch_reader(features , labels , batch_size):\n",
    "        l = loss(torch.matmul(x,w)+b,y)\n",
    "        l.sum().backward()\n",
    "        SGD(batch_size,lr,[w,b])\n",
    "    with torch.no_grad():\n",
    "        train_l = loss(torch.matmul(x,w)+b,y)\n",
    "        print(f'epoch{epoch+1},loss{float(train_l.mean()):f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f78bef-0446-4f5f-94c9-c0ffc94b3e1b",
   "metadata": {},
   "source": [
    "## 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07a8687b-2a35-4602-933a-428a6a734c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0003],\n",
      "        [-3.1000],\n",
      "        [ 3.9998]], requires_grad=True) tensor([4.2000], requires_grad=True)\n",
      "w的误差:tensor([-3.1161e-04,  3.4571e-05,  1.5330e-04], grad_fn=<SubBackward0>)\n",
      "b的误差:tensor([1.7643e-05], grad_fn=<RsubBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(w,b)\n",
    "print(f'w的误差:{w_true - w.reshape(w_true.shape)}')\n",
    "print(f'b的误差:{b_true - b}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
